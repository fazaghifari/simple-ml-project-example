{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "922b8e9d-970b-4e3f-813c-6f36f3316e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import sklearn\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c73033e0-875e-419c-8ef4-834e0e40273a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from string import punctuation\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28644e87-99b8-4709-9278-186eeca540ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b989a13-be38-4e19-bfc2-43f617cc031f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/comments_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "67b82811-0280-48fb-8f91-d69688feb0e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "      <th>lang</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic  \\\n",
       "0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
       "2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3  0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate     lang  \n",
       "0             0        0       0       0              0  English  \n",
       "1             0        0       0       0              0  English  \n",
       "2             0        0       0       0              0  English  \n",
       "3             0        0       0       0              0  English  \n",
       "4             0        0       0       0              0  English  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd718015-663f-4588-b5c4-290905cebcfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 220653 entries, 0 to 220652\n",
      "Data columns (total 9 columns):\n",
      " #   Column         Non-Null Count   Dtype \n",
      "---  ------         --------------   ----- \n",
      " 0   id             220653 non-null  object\n",
      " 1   comment_text   220653 non-null  object\n",
      " 2   toxic          220653 non-null  int64 \n",
      " 3   severe_toxic   220653 non-null  int64 \n",
      " 4   obscene        220653 non-null  int64 \n",
      " 5   threat         220653 non-null  int64 \n",
      " 6   insult         220653 non-null  int64 \n",
      " 7   identity_hate  220653 non-null  int64 \n",
      " 8   lang           220653 non-null  object\n",
      "dtypes: int64(6), object(3)\n",
      "memory usage: 15.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()\n",
    "# No NaN values observed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "16e6061f-2f26-4726-8719-a5b25e2a09d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id               220653\n",
       "comment_text     220653\n",
       "toxic                 2\n",
       "severe_toxic          2\n",
       "obscene               2\n",
       "threat                2\n",
       "insult                2\n",
       "identity_hate         2\n",
       "lang                  1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a7086f6-a07b-4e20-9762-6c97f52e14e2",
   "metadata": {},
   "source": [
    "# What We Have\n",
    "\n",
    "Now, we have several columns:\n",
    "- id: The comment identifier\n",
    "- comment_txt: Text in the comment\n",
    "- toxic: comment is toxic or not\n",
    "- severe_toxic: comment is severely toxic or not\n",
    "- obscene: comment is obscene or not\n",
    "- threat: comment is threat or not\n",
    "- insult: comment is insult or not\n",
    "- identity_hate: comment is identity_hate or not\n",
    "- lang: language\n",
    "\n",
    "It seems we have multiple targets here. Now, let's count the frequency ratio of each target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1574cc2d-0d56-4c8a-92c0-5a9e1eccf5eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = ['toxic','severe_toxic','obscene','threat','insult','identity_hate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "47d13f27-3a33-42d1-974c-f7bc08214b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We want to count the number of \"yes\" in each target and divide by the number of observation\n",
    "def count_ratio(df, targets):\n",
    "    ratio_dict = {}\n",
    "    for target in targets:\n",
    "        ratio_dict[target] = df[target].sum()/len(df)\n",
    "    return ratio_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ef19ab10-37c8-48d0-887d-0c2f8781c59a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'toxic': 0.09495905335526823,\n",
       " 'severe_toxic': 0.00848844112701844,\n",
       " 'obscene': 0.053541080338812524,\n",
       " 'threat': 0.003099889872333483,\n",
       " 'insult': 0.05013301428034062,\n",
       " 'identity_hate': 0.009349521647111074}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_ratio(df,targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce0d4d64-122b-4ed9-9a39-b58d5ef13f20",
   "metadata": {},
   "source": [
    "Or, more elegant way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "435fd943-a079-4558-ab8c-af18d92a92e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "toxic            0.094959\n",
       "obscene          0.053541\n",
       "insult           0.050133\n",
       "identity_hate    0.009350\n",
       "severe_toxic     0.008488\n",
       "threat           0.003100\n",
       "dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[targets].mean().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "236e39bc-bf9c-45f6-996a-9d5757855044",
   "metadata": {},
   "source": [
    "Dang, we have an imbalanced problem here.\n",
    "\n",
    "It seems that toxic is the most frequent. But is 'toxic' a generalization from the others?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bdc74b9d-8008-4ad5-a6eb-1f75e95ba584",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "toxic            0\n",
       "severe_toxic     0\n",
       "obscene          0\n",
       "threat           0\n",
       "insult           0\n",
       "identity_hate    0\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[0][targets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "53e56aa7-7457-42a4-aa68-bbefac744d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_generalization(df, targets):\n",
    "    \"\"\"\n",
    "    Checking if there any rows that non-toxic but belongs to other categories.\n",
    "    We want to know if \"toxic\" is the generalization from the others.\n",
    "    \"\"\"\n",
    "    counter = 0\n",
    "    targets = targets[1:]  #remove \"toxic\"\n",
    "\n",
    "    for idx, row in tqdm(df.iterrows(), total=df.shape[0]):  # iterate over dataframe, add progress bar\n",
    "        toxic = row['toxic']   # get the toxic value\n",
    "        other = row[targets].sum()  # sum all the others\n",
    "        if toxic:  # if toxic, then let it go\n",
    "            pass\n",
    "        else:  # if non-toxic and the other is non zero then add the counter\n",
    "            if other != 0:\n",
    "                counter += 1\n",
    "    return counter / len(df[df.toxic == 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9d148a16-a658-4367-a1d4-2353ef0fc118",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 220653/220653 [02:24<00:00, 1530.01it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.051018947167470054"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_generalization(df,targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeda90d4-73e2-4c2a-a180-6c7d839b2055",
   "metadata": {},
   "source": [
    "Well, it seems toxic is not a generalizaton because there are cases where non-toxic but belong to other class(es).\n",
    "\n",
    "For this case, we should use the multi-label classification approach. However, for the sake of simplicity of this example. Let's stick only to `toxic`.\n",
    "\n",
    "So later, we'll drop the other targets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25048700-9bd4-43b8-8eb6-c92580a5cc54",
   "metadata": {},
   "source": [
    "## Train-test-valid split\n",
    "\n",
    "Before we go further, let's stop here and go back to the presentation again."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bcebb5d-4f74-467e-98da-8a73bb8023c6",
   "metadata": {},
   "source": [
    "So, before we do anything that can alter the dataset, we should split our dataset first to prevent any data leakage. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "45de202b-f1f6-4372-939e-beab43d47e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, let's separate the features and target columns\n",
    "def split_xy(df, x_col, y_col):\n",
    "    x_col = ['id']+x_col\n",
    "    y_col = ['id']+y_col\n",
    "    return df[x_col], df[y_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5a7f51f3-f0fd-42e8-8d89-b521aeb0fabc",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_all, y_all = split_xy(df, ['comment_text'], ['toxic'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2fd19f0-1f92-4005-a41d-8892a783f7cd",
   "metadata": {},
   "source": [
    "The Features and target now separated, let's split the train-test-valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0b70ca4a-89b3-41a4-b8d2-a89967a14f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stratify_col(y, stratify_col):\n",
    "    if stratify_col is None:\n",
    "        stratification = None\n",
    "    else:\n",
    "        stratification = y[stratify_col]\n",
    "    \n",
    "    return stratification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "00d43d42-297a-4204-b1ee-26f5854efaf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_split_data(x, y, stratify_col=None, TEST_SIZE=0.2):\n",
    "    \n",
    "    strat_train = get_stratify_col(y, stratify_col)\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y,\n",
    "                                       stratify = strat_train,\n",
    "                                       test_size= TEST_SIZE*2,\n",
    "                                       random_state= 42)\n",
    "    \n",
    "    strat_test = get_stratify_col(y_test, stratify_col)\n",
    "    x_valid, x_test, y_valid, y_test = train_test_split(x_test, y_test,\n",
    "                                       stratify = strat_test,\n",
    "                                       test_size= 0.5,\n",
    "                                       random_state= 42)\n",
    "    \n",
    "    return x_train, y_train, x_valid, y_valid, x_test, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79418692-ba6c-4ae9-aaaa-c1658b95faf8",
   "metadata": {},
   "source": [
    "Actually, there are some schemes can be used:\n",
    "- Split train:test with 0.8:0.2 then split the splitted train into train:valid with 0.8:0.2\n",
    "- Split train:valid:test with 0.8:0.2:0.2 like shown in the code above\n",
    "\n",
    "It's arbitrary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd412128-d8a7-4552-932b-0f23c9a31e24",
   "metadata": {},
   "source": [
    "Question:\n",
    "- Why we need stratification? [answer](https://stackoverflow.com/questions/29438265/stratified-train-test-split-in-scikit-learn#:~:text=As%20such%2C%20it%20is%20desirable,a%20stratified%20train%2Dtest%20split.)\n",
    "- Can stratification works with multi-label? [answer](https://stackoverflow.com/questions/52434568/how-to-pickle-a-sklearn-pipeline-for-multi-label-classifier-one-vs-rest-classifi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c22c8200-52d2-409f-bf89-abc55f5f1bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train,x_valid, y_valid,x_test, y_test = run_split_data(x_all, y_all, 'toxic', 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2487ec66-16cc-43f3-baf5-7916ee41a751",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ratio in training data: 0.09496113784169619\n",
      "Ratio in validation data: 0.09496725657700936\n",
      "Ratio in testing data: 0.09494459676871134\n"
     ]
    }
   ],
   "source": [
    "print(f\"Ratio in training data: {y_train['toxic'].mean()}\")\n",
    "print(f\"Ratio in validation data: {y_valid['toxic'].mean()}\")\n",
    "print(f\"Ratio in testing data: {y_test['toxic'].mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b28cdc35-d159-430d-8aa7-d5b0a9fa3d62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length training data: 132391\n",
      "Length validation data: 44131\n",
      "Length testing data: 44131\n"
     ]
    }
   ],
   "source": [
    "print(f\"Length training data: {len(x_train)}\")\n",
    "print(f\"Length validation data: {len(x_valid)}\")\n",
    "print(f\"Length testing data: {len(x_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39e8fbba-cd11-4eb5-8dff-a15311f9ce3b",
   "metadata": {},
   "source": [
    "It's important to save the intermediate result. This can be very useful for debugging in the production stage. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8abf56de-570e-4ceb-8cb0-cc4254902dd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../output/y_test.pkl']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(x_train, \"../output/x_train.pkl\")\n",
    "joblib.dump(y_train, \"../output/y_train.pkl\")\n",
    "joblib.dump(x_valid, \"../output/x_valid.pkl\")\n",
    "joblib.dump(y_valid, \"../output/y_valid.pkl\")\n",
    "joblib.dump(x_test, \"../output/x_test.pkl\")\n",
    "joblib.dump(y_test, \"../output/y_test.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caa81453-7257-428e-b49b-a3efafac97ca",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc0eef7b-f283-4c84-9e36-51a748d735ef",
   "metadata": {},
   "source": [
    "In the previous steps, we only have `comment_text` as our only features. Thus, the possible next step is to **generate new features**.\n",
    "\n",
    "But before we proceed to that step, we'd like to perform data processing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce1ab74-5a71-42e1-bb62-881ee9482403",
   "metadata": {},
   "source": [
    "## Lower Characters\n",
    "\n",
    "What we want to do here is to make all of the characters in the `comment_text` in lowercase. Why?\n",
    "- Standardizing all text\n",
    "- Because computer will treat \"Bekasi\" and \"bekasi\" as different thing\n",
    "- Thus, that can caused problem in the word vectorizer. Because \"Bekasi\" and \"bekasi\" will be different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0af268fd-6240-4f65-b8d4-b65e5a95ff7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lowercase_char(df_in):\n",
    "    df = df_in.copy()  # Avoid modifying the main dataframe\n",
    "    df['comment_text'] = df['comment_text'].str.lower()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b81d0653-ee3f-4cba-b37c-942c98274d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_lower = lowercase_char(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0086fc0b-d10f-4087-b7b3-1f3ab8ee2974",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>162870</th>\n",
       "      <td>10c4b10bd953900d</td>\n",
       "      <td>\" \\n\\n :::you're splitting hairs - the idea th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170883</th>\n",
       "      <td>31ad9c8987c1a64c</td>\n",
       "      <td>:i simply undid your edit that removed sourced...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175275</th>\n",
       "      <td>436b574a54215710</td>\n",
       "      <td>\" \\n\\n == resident evil mention... == \\n\\n i'd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28519</th>\n",
       "      <td>4bda577fb3caa772</td>\n",
       "      <td>troops off to re-register</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36661</th>\n",
       "      <td>6258dbad0e1b24da</td>\n",
       "      <td>\"\\n\\ni fixed some grammar. just basic things t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id                                       comment_text\n",
       "162870  10c4b10bd953900d  \" \\n\\n :::you're splitting hairs - the idea th...\n",
       "170883  31ad9c8987c1a64c  :i simply undid your edit that removed sourced...\n",
       "175275  436b574a54215710  \" \\n\\n == resident evil mention... == \\n\\n i'd...\n",
       "28519   4bda577fb3caa772                          troops off to re-register\n",
       "36661   6258dbad0e1b24da  \"\\n\\ni fixed some grammar. just basic things t..."
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_lower.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2654c39a-64ad-450f-a0cd-99c79cb1b1f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>162870</th>\n",
       "      <td>10c4b10bd953900d</td>\n",
       "      <td>\" \\n\\n :::You're splitting hairs - the idea th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170883</th>\n",
       "      <td>31ad9c8987c1a64c</td>\n",
       "      <td>:I simply undid your edit that removed sourced...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175275</th>\n",
       "      <td>436b574a54215710</td>\n",
       "      <td>\" \\n\\n == Resident Evil mention... == \\n\\n I'd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28519</th>\n",
       "      <td>4bda577fb3caa772</td>\n",
       "      <td>troops off to re-register</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36661</th>\n",
       "      <td>6258dbad0e1b24da</td>\n",
       "      <td>\"\\n\\nI fixed some grammar. Just basic things t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id                                       comment_text\n",
       "162870  10c4b10bd953900d  \" \\n\\n :::You're splitting hairs - the idea th...\n",
       "170883  31ad9c8987c1a64c  :I simply undid your edit that removed sourced...\n",
       "175275  436b574a54215710  \" \\n\\n == Resident Evil mention... == \\n\\n I'd...\n",
       "28519   4bda577fb3caa772                          troops off to re-register\n",
       "36661   6258dbad0e1b24da  \"\\n\\nI fixed some grammar. Just basic things t..."
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d8cc224-0b01-4b66-be70-420639e8264c",
   "metadata": {},
   "source": [
    "## Decontracting words\n",
    "\n",
    "Expanding words such as \"'t to not\", \"'re to are\". Why?\n",
    "- Making text more consistent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4e348de4-6d08-442d-bd30-535c60b79be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/a/47091490/14472314\n",
    "def phrase_decontraction(phrase):\n",
    "    # specific\n",
    "    phrase = re.sub(r\"won\\'t\", \"will not\", phrase)\n",
    "    phrase = re.sub(r\"can\\'t\", \"can not\", phrase)\n",
    "\n",
    "    # general\n",
    "    phrase = re.sub(r\"n\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'re\", \" are\", phrase)\n",
    "    phrase = re.sub(r\"\\'s\", \" is\", phrase)\n",
    "    phrase = re.sub(r\"\\'d\", \" would\", phrase)\n",
    "    phrase = re.sub(r\"\\'ll\", \" will\", phrase)\n",
    "    phrase = re.sub(r\"\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'ve\", \" have\", phrase)\n",
    "    phrase = re.sub(r\"\\'m\", \" am\", phrase)\n",
    "    return phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "38fb309b-6ee8-4ceb-a28c-ab606f112d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decontract(df_in):\n",
    "    df = df_in.copy()  # Avoid modifying the main dataframe\n",
    "    df['comment_text'] = df['comment_text'].progress_apply(phrase_decontraction)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0ee7b701-77af-42d9-8948-7e5d3433f495",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 132391/132391 [00:02<00:00, 47127.52it/s]\n"
     ]
    }
   ],
   "source": [
    "x_train_decontract = decontract(x_train_lower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "70f378b7-dfde-43d6-8f5a-9f93686c5b00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>162870</th>\n",
       "      <td>10c4b10bd953900d</td>\n",
       "      <td>\" \\n\\n :::you are splitting hairs - the idea t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170883</th>\n",
       "      <td>31ad9c8987c1a64c</td>\n",
       "      <td>:i simply undid your edit that removed sourced...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175275</th>\n",
       "      <td>436b574a54215710</td>\n",
       "      <td>\" \\n\\n == resident evil mention... == \\n\\n i w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28519</th>\n",
       "      <td>4bda577fb3caa772</td>\n",
       "      <td>troops off to re-register</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36661</th>\n",
       "      <td>6258dbad0e1b24da</td>\n",
       "      <td>\"\\n\\ni fixed some grammar. just basic things t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id                                       comment_text\n",
       "162870  10c4b10bd953900d  \" \\n\\n :::you are splitting hairs - the idea t...\n",
       "170883  31ad9c8987c1a64c  :i simply undid your edit that removed sourced...\n",
       "175275  436b574a54215710  \" \\n\\n == resident evil mention... == \\n\\n i w...\n",
       "28519   4bda577fb3caa772                          troops off to re-register\n",
       "36661   6258dbad0e1b24da  \"\\n\\ni fixed some grammar. just basic things t..."
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_decontract.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "81bee745-cf2a-47ce-8b47-bc8da0bc36fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>162870</th>\n",
       "      <td>10c4b10bd953900d</td>\n",
       "      <td>\" \\n\\n :::you're splitting hairs - the idea th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170883</th>\n",
       "      <td>31ad9c8987c1a64c</td>\n",
       "      <td>:i simply undid your edit that removed sourced...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175275</th>\n",
       "      <td>436b574a54215710</td>\n",
       "      <td>\" \\n\\n == resident evil mention... == \\n\\n i'd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28519</th>\n",
       "      <td>4bda577fb3caa772</td>\n",
       "      <td>troops off to re-register</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36661</th>\n",
       "      <td>6258dbad0e1b24da</td>\n",
       "      <td>\"\\n\\ni fixed some grammar. just basic things t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id                                       comment_text\n",
       "162870  10c4b10bd953900d  \" \\n\\n :::you're splitting hairs - the idea th...\n",
       "170883  31ad9c8987c1a64c  :i simply undid your edit that removed sourced...\n",
       "175275  436b574a54215710  \" \\n\\n == resident evil mention... == \\n\\n i'd...\n",
       "28519   4bda577fb3caa772                          troops off to re-register\n",
       "36661   6258dbad0e1b24da  \"\\n\\ni fixed some grammar. just basic things t..."
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_lower.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ef6e109-93dd-4bf7-9f08-42770c59de37",
   "metadata": {},
   "source": [
    "## Removing numbers\n",
    "\n",
    "Numbers should not affect the toxicity of a comment. Thus, we want to remove the numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ed476813-9b43-40c6-a1e0-f3368828a5a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_numbers(df_in):\n",
    "    df = df_in.copy()  # Avoid modifying the main dataframe\n",
    "    df['comment_text'] = df['comment_text'].progress_apply(lambda x: ''.join(string for string in x if not string.isdigit()))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e1c40888-e969-4964-a2f0-159233128e48",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 132391/132391 [00:07<00:00, 16883.27it/s]\n"
     ]
    }
   ],
   "source": [
    "x_train_nonum = remove_numbers(x_train_decontract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ee53629b-d2e4-4352-a8d6-6b54fa1cae4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>162870</th>\n",
       "      <td>10c4b10bd953900d</td>\n",
       "      <td>\" \\n\\n :::you are splitting hairs - the idea t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170883</th>\n",
       "      <td>31ad9c8987c1a64c</td>\n",
       "      <td>:i simply undid your edit that removed sourced...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175275</th>\n",
       "      <td>436b574a54215710</td>\n",
       "      <td>\" \\n\\n == resident evil mention... == \\n\\n i w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28519</th>\n",
       "      <td>4bda577fb3caa772</td>\n",
       "      <td>troops off to re-register</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36661</th>\n",
       "      <td>6258dbad0e1b24da</td>\n",
       "      <td>\"\\n\\ni fixed some grammar. just basic things t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>644</th>\n",
       "      <td>01c10add8c4e0491</td>\n",
       "      <td>well, you never answered my question about you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74556</th>\n",
       "      <td>c858e7772e89b5b5</td>\n",
       "      <td>\"\\n dan, we do not repeat things that are mino...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14097</th>\n",
       "      <td>2558cc6a8ad094eb</td>\n",
       "      <td>\"\\nthis user has a limited history and is not ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199420</th>\n",
       "      <td>a76bd844beda1649</td>\n",
       "      <td>== template:navigation on meta tab colour  == ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196214</th>\n",
       "      <td>9a0c7dc857f9fad4</td>\n",
       "      <td>brack obama is a hairy fairy.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>132391 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id                                       comment_text\n",
       "162870  10c4b10bd953900d  \" \\n\\n :::you are splitting hairs - the idea t...\n",
       "170883  31ad9c8987c1a64c  :i simply undid your edit that removed sourced...\n",
       "175275  436b574a54215710  \" \\n\\n == resident evil mention... == \\n\\n i w...\n",
       "28519   4bda577fb3caa772                          troops off to re-register\n",
       "36661   6258dbad0e1b24da  \"\\n\\ni fixed some grammar. just basic things t...\n",
       "...                  ...                                                ...\n",
       "644     01c10add8c4e0491  well, you never answered my question about you...\n",
       "74556   c858e7772e89b5b5  \"\\n dan, we do not repeat things that are mino...\n",
       "14097   2558cc6a8ad094eb  \"\\nthis user has a limited history and is not ...\n",
       "199420  a76bd844beda1649  == template:navigation on meta tab colour  == ...\n",
       "196214  9a0c7dc857f9fad4                      brack obama is a hairy fairy.\n",
       "\n",
       "[132391 rows x 2 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_nonum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53975fb6-f3cc-4785-8967-da29aa456d4d",
   "metadata": {},
   "source": [
    "# Remove punctuations\n",
    "\n",
    "We can also consider punctuations as a noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8c8ec6e4-43d8-4b32-b86a-141001f250de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punc(df_in):\n",
    "    df = df_in.copy()  # Avoid modifying the main dataframe\n",
    "    df['comment_text'] = df['comment_text'].str.replace(f'[{punctuation}]', ' ', regex=True )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4071644c-5d5e-47f4-b381-ee1de5bbc51a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_nopunc = remove_punc(x_train_nonum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9082fb26-1688-4364-9091-4eef92f60b80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>162870</th>\n",
       "      <td>10c4b10bd953900d</td>\n",
       "      <td>\\n\\n    you are splitting hairs   the idea t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170883</th>\n",
       "      <td>31ad9c8987c1a64c</td>\n",
       "      <td>i simply undid your edit that removed sourced...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175275</th>\n",
       "      <td>436b574a54215710</td>\n",
       "      <td>\\n\\n    resident evil mention       \\n\\n i w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28519</th>\n",
       "      <td>4bda577fb3caa772</td>\n",
       "      <td>troops off to re register</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36661</th>\n",
       "      <td>6258dbad0e1b24da</td>\n",
       "      <td>\\n\\ni fixed some grammar  just basic things t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id                                       comment_text\n",
       "162870  10c4b10bd953900d    \\n\\n    you are splitting hairs   the idea t...\n",
       "170883  31ad9c8987c1a64c   i simply undid your edit that removed sourced...\n",
       "175275  436b574a54215710    \\n\\n    resident evil mention       \\n\\n i w...\n",
       "28519   4bda577fb3caa772                          troops off to re register\n",
       "36661   6258dbad0e1b24da   \\n\\ni fixed some grammar  just basic things t..."
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_nopunc.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d0c4a14-ef06-451e-9e21-388d386b2a7c",
   "metadata": {},
   "source": [
    "## Removing Whitespaces\n",
    "\n",
    "Whitespace can also be considered as a noise. Moreover, we still have the newline characters \"\\n\". We want to remove them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9b486603-b1a7-4a77-8ce8-7e37376ed401",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_whitespace(df_in):\n",
    "    df = df_in.copy()  # Avoid modifying the main dataframe\n",
    "    df['comment_text'] = df['comment_text'].progress_apply(lambda x: \" \".join(x.split()))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b56d7640-26ea-4e89-937f-b465a9e9c5db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 132391/132391 [00:01<00:00, 93976.35it/s]\n"
     ]
    }
   ],
   "source": [
    "x_train_nowhitespace = remove_whitespace(x_train_nopunc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8b360c4c-2bb1-4d71-97b6-fd53c681067e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>162870</th>\n",
       "      <td>10c4b10bd953900d</td>\n",
       "      <td>you are splitting hairs the idea that it could...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170883</th>\n",
       "      <td>31ad9c8987c1a64c</td>\n",
       "      <td>i simply undid your edit that removed sourced ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175275</th>\n",
       "      <td>436b574a54215710</td>\n",
       "      <td>resident evil mention i would just like to add...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28519</th>\n",
       "      <td>4bda577fb3caa772</td>\n",
       "      <td>troops off to re register</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36661</th>\n",
       "      <td>6258dbad0e1b24da</td>\n",
       "      <td>i fixed some grammar just basic things that we...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id                                       comment_text\n",
       "162870  10c4b10bd953900d  you are splitting hairs the idea that it could...\n",
       "170883  31ad9c8987c1a64c  i simply undid your edit that removed sourced ...\n",
       "175275  436b574a54215710  resident evil mention i would just like to add...\n",
       "28519   4bda577fb3caa772                          troops off to re register\n",
       "36661   6258dbad0e1b24da  i fixed some grammar just basic things that we..."
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_nowhitespace.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a3a64c-3af1-4c5a-952e-b55717fe44f2",
   "metadata": {},
   "source": [
    "# Removing Stopwords\n",
    "\n",
    "Stopwords are abundant, removing stopwords could give more focus to the important information.\n",
    "\n",
    "Because the text is in english, we could use predefined stopwords from nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d0153a4b-1e9d-4009-b4a4-e7f166f247a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ghifa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\ghifa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8febca99-248a-4d44-9149-4b966eb10faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_stopwords = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "eacd4384-09e6-4a9d-bfcc-4248c6934c93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\"]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eng_stopwords[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0eb932bf-c159-41e7-8ed0-f49ebcaa0970",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stop(df_in, eng_stopwords):\n",
    "    df = df_in.copy()  # Avoid modifying the main dataframe\n",
    "    df['comment_text'] = df['comment_text'].progress_apply(lambda x: \" \".join([word for word in nltk.word_tokenize(x) if word not in eng_stopwords]))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8fb6e748-9379-489b-9cd7-ece41d9d391d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 132391/132391 [01:08<00:00, 1919.19it/s]\n"
     ]
    }
   ],
   "source": [
    "x_train_nostop = remove_stop(x_train_nowhitespace, eng_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "95229baa-38f7-4408-94a8-e7f48bf386da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>162870</th>\n",
       "      <td>10c4b10bd953900d</td>\n",
       "      <td>splitting hairs idea could another barack obam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170883</th>\n",
       "      <td>31ad9c8987c1a64c</td>\n",
       "      <td>simply undid edit removed sourced information ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175275</th>\n",
       "      <td>436b574a54215710</td>\n",
       "      <td>resident evil mention would like add something...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28519</th>\n",
       "      <td>4bda577fb3caa772</td>\n",
       "      <td>troops register</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36661</th>\n",
       "      <td>6258dbad0e1b24da</td>\n",
       "      <td>fixed grammar basic things incorrect — precedi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id                                       comment_text\n",
       "162870  10c4b10bd953900d  splitting hairs idea could another barack obam...\n",
       "170883  31ad9c8987c1a64c  simply undid edit removed sourced information ...\n",
       "175275  436b574a54215710  resident evil mention would like add something...\n",
       "28519   4bda577fb3caa772                                    troops register\n",
       "36661   6258dbad0e1b24da  fixed grammar basic things incorrect — precedi..."
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_nostop.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a45c2ec-69f0-444c-aa88-5c17bb1800b8",
   "metadata": {},
   "source": [
    "## Stemming / Lemmatization\n",
    "\n",
    "* **Goal:** reduce inflection in words to their root form.\n",
    "* **Stemming:** Removing prefix or suffix (e.g. explanation --> explan)\n",
    "* **Lemmatization:** Properly ensure the canonical form (e.g. explanation --> explain)\n",
    "\n",
    "Sometimes stemming/lemmatization aren't necessary, but sometimes are helpful.\n",
    "\n",
    "We don't know the effect until we try. Later, we'll try without stemming/lemmatization.\n",
    "\n",
    "But if you want to know how to use it:\n",
    "\n",
    "> note: These process are much slower than stopwords removal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ee0a3dd-12a4-4a4b-b86d-7b33ff2dbda5",
   "metadata": {},
   "source": [
    "### Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "752f3953-3eea-44d7-9b1f-cb6f625ab070",
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_stemmer = SnowballStemmer('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "df9439b1-c75b-4d64-8029-73026cf84993",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stemmer(df_in, eng_stemmer):\n",
    "    df = df_in.copy()  # Avoid modifying the main dataframe\n",
    "    df['comment_text'] = df['comment_text'].progress_apply(lambda x: \" \".join([eng_stemmer.stem(word) for sent_words in nltk.word_tokenize(x) for word in nltk.word_tokenize(sent_words)]))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4744c530-6443-42ba-ba35-8dfb947a45c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 132391/132391 [09:16<00:00, 237.83it/s]\n"
     ]
    }
   ],
   "source": [
    "x_train_stemmed = stemmer(x_train_nostop, eng_stemmer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "340a2eb9-645f-4609-9501-b8fde7a6c7c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>162870</th>\n",
       "      <td>10c4b10bd953900d</td>\n",
       "      <td>split hair idea could anoth barack obama ridic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170883</th>\n",
       "      <td>31ad9c8987c1a64c</td>\n",
       "      <td>simpli undid edit remov sourc inform without e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175275</th>\n",
       "      <td>436b574a54215710</td>\n",
       "      <td>resid evil mention would like add someth bette...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28519</th>\n",
       "      <td>4bda577fb3caa772</td>\n",
       "      <td>troop regist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36661</th>\n",
       "      <td>6258dbad0e1b24da</td>\n",
       "      <td>fix grammar basic thing incorrect — preced jmi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id                                       comment_text\n",
       "162870  10c4b10bd953900d  split hair idea could anoth barack obama ridic...\n",
       "170883  31ad9c8987c1a64c  simpli undid edit remov sourc inform without e...\n",
       "175275  436b574a54215710  resid evil mention would like add someth bette...\n",
       "28519   4bda577fb3caa772                                       troop regist\n",
       "36661   6258dbad0e1b24da  fix grammar basic thing incorrect — preced jmi..."
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_stemmed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73008dfe-d632-4e85-8953-ce1cafce8443",
   "metadata": {},
   "source": [
    "### Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1a619dbc-4888-4b8d-ad0b-74f46fd3cd05",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\ghifa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\ghifa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5a35b535-1e18-437d-bc5e-bb95535d3bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordnet_lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0b60d849-4089-4f69-ac27-2b294820c6ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatizer(df_in, eng_lemmatizer):\n",
    "    df = df_in.copy()  # Avoid modifying the main dataframe\n",
    "    df['comment_text'] = df['comment_text'].progress_apply(lambda x: \" \".join([eng_lemmatizer.lemmatize(word, pos='v') for sent_words in nltk.word_tokenize(x) for word in nltk.word_tokenize(sent_words)]))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8b666e8c-1aaa-4f12-9128-963006ec6d1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 132391/132391 [08:09<00:00, 270.35it/s]\n"
     ]
    }
   ],
   "source": [
    "x_train_lemmatized = lemmatizer(x_train_nostop, wordnet_lemmatizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "dc08ac54-6b54-407d-b151-7646873ce3d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>162870</th>\n",
       "      <td>10c4b10bd953900d</td>\n",
       "      <td>split hairs idea could another barack obama ri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170883</th>\n",
       "      <td>31ad9c8987c1a64c</td>\n",
       "      <td>simply undo edit remove source information wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175275</th>\n",
       "      <td>436b574a54215710</td>\n",
       "      <td>resident evil mention would like add something...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28519</th>\n",
       "      <td>4bda577fb3caa772</td>\n",
       "      <td>troop register</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36661</th>\n",
       "      <td>6258dbad0e1b24da</td>\n",
       "      <td>fix grammar basic things incorrect — precede j...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>644</th>\n",
       "      <td>01c10add8c4e0491</td>\n",
       "      <td>well never answer question specific intention ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74556</th>\n",
       "      <td>c858e7772e89b5b5</td>\n",
       "      <td>dan repeat things minority opinions obviously ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14097</th>\n",
       "      <td>2558cc6a8ad094eb</td>\n",
       "      <td>user limit history register user reply instead...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199420</th>\n",
       "      <td>a76bd844beda1649</td>\n",
       "      <td>template navigation meta tab colour hi thehelp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196214</th>\n",
       "      <td>9a0c7dc857f9fad4</td>\n",
       "      <td>brack obama hairy fairy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>132391 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id                                       comment_text\n",
       "162870  10c4b10bd953900d  split hairs idea could another barack obama ri...\n",
       "170883  31ad9c8987c1a64c  simply undo edit remove source information wit...\n",
       "175275  436b574a54215710  resident evil mention would like add something...\n",
       "28519   4bda577fb3caa772                                     troop register\n",
       "36661   6258dbad0e1b24da  fix grammar basic things incorrect — precede j...\n",
       "...                  ...                                                ...\n",
       "644     01c10add8c4e0491  well never answer question specific intention ...\n",
       "74556   c858e7772e89b5b5  dan repeat things minority opinions obviously ...\n",
       "14097   2558cc6a8ad094eb  user limit history register user reply instead...\n",
       "199420  a76bd844beda1649  template navigation meta tab colour hi thehelp...\n",
       "196214  9a0c7dc857f9fad4                            brack obama hairy fairy\n",
       "\n",
       "[132391 rows x 2 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_lemmatized"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b11cf0a9-d39b-473c-99ec-4693ea3c4c64",
   "metadata": {},
   "source": [
    "## Recap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7143b369-b94a-4b1d-ad97-923407c47fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_preprocess(df_in, eng_stopwords):\n",
    "    df = df_in.copy()\n",
    "    df = lowercase_char(df)\n",
    "    df = decontract(df)\n",
    "    df = remove_numbers(df)\n",
    "    df = remove_punc(df)\n",
    "    df = remove_whitespace(df)\n",
    "    df = remove_stop(df, eng_stopwords)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "663bc47e-0832-4dd9-a1c9-ff58d771359f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_list = [x_train,x_valid,x_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8211c11-0541-4dbe-9e2e-62d9610869b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_preprocessed = []\n",
    "for x in tqdm(x_list):\n",
    "    temp = main_preprocess(x, eng_stopwords)\n",
    "    x_preprocessed.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9bdf54ff-1f3c-425b-a519-4cb503894fc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [00:00, 13.86it/s]\n"
     ]
    }
   ],
   "source": [
    "name = ['train','valid','test']\n",
    "for i,x in tqdm(enumerate(x_preprocessed)):\n",
    "    joblib.dump(x, f\"../output/x_{name[i]}_preprocessed.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eb166d0-54dc-4038-bf54-55032d788a49",
   "metadata": {},
   "source": [
    "# EDA\n",
    "\n",
    "We want to analyze the text in order to understand more the case's context. Sometimes, EDA will also helps us to give new idea for new features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ba6585ad-36e2-4baf-95bc-a6c1808b6dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_preprocessed, x_valid_preprocessed, x_test_preprocessed = x_preprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "cf21c98f-c6d7-46a7-8253-8dc0ca57cb56",
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_toxic = CountVectorizer(stop_words=stopwords.words('english'))\n",
    "x_toxic = vec_toxic.fit_transform(x_train_preprocessed[y_train.toxic == 1]['comment_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "78ce97d3-6dbe-4f2c-87ea-3096187496a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_nontoxic = CountVectorizer(stop_words=stopwords.words('english'))\n",
    "x_nontoxic = vec_nontoxic.fit_transform(x_train_preprocessed[y_train.toxic == 0]['comment_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f4516cc9-9134-4904-acd5-c6fa8b2b613f",
   "metadata": {},
   "outputs": [],
   "source": [
    "toxic_words = pd.DataFrame({\n",
    "    'word': vec_toxic.get_feature_names_out(),\n",
    "    'freq': np.array(x_toxic.sum(axis=0)).flatten()\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "20fc8857-7846-4d3b-9c84-ba6f2ec4470d",
   "metadata": {},
   "outputs": [],
   "source": [
    "nontoxic_words = pd.DataFrame({\n",
    "    'word': vec_nontoxic.get_feature_names_out(),\n",
    "    'freq': np.array(x_nontoxic.sum(axis=0)).flatten()\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "1bd135f1-a13b-4aba-8da9-e5d3ab0b6d95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10009</th>\n",
       "      <td>fuck</td>\n",
       "      <td>4224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10046</th>\n",
       "      <td>fucking</td>\n",
       "      <td>3025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14839</th>\n",
       "      <td>like</td>\n",
       "      <td>2910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27837</th>\n",
       "      <td>wikipedia</td>\n",
       "      <td>2528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24433</th>\n",
       "      <td>suck</td>\n",
       "      <td>2317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22763</th>\n",
       "      <td>shit</td>\n",
       "      <td>2259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17247</th>\n",
       "      <td>nigger</td>\n",
       "      <td>2171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10366</th>\n",
       "      <td>gay</td>\n",
       "      <td>1990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9106</th>\n",
       "      <td>fat</td>\n",
       "      <td>1986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1522</th>\n",
       "      <td>ass</td>\n",
       "      <td>1912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10513</th>\n",
       "      <td>get</td>\n",
       "      <td>1734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18294</th>\n",
       "      <td>page</td>\n",
       "      <td>1652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6872</th>\n",
       "      <td>die</td>\n",
       "      <td>1639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14236</th>\n",
       "      <td>know</td>\n",
       "      <td>1582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10705</th>\n",
       "      <td>go</td>\n",
       "      <td>1569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24326</th>\n",
       "      <td>stupid</td>\n",
       "      <td>1551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2674</th>\n",
       "      <td>bitch</td>\n",
       "      <td>1531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18733</th>\n",
       "      <td>people</td>\n",
       "      <td>1465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5877</th>\n",
       "      <td>cunt</td>\n",
       "      <td>1452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11496</th>\n",
       "      <td>hate</td>\n",
       "      <td>1444</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            word  freq\n",
       "10009       fuck  4224\n",
       "10046    fucking  3025\n",
       "14839       like  2910\n",
       "27837  wikipedia  2528\n",
       "24433       suck  2317\n",
       "22763       shit  2259\n",
       "17247     nigger  2171\n",
       "10366        gay  1990\n",
       "9106         fat  1986\n",
       "1522         ass  1912\n",
       "10513        get  1734\n",
       "18294       page  1652\n",
       "6872         die  1639\n",
       "14236       know  1582\n",
       "10705         go  1569\n",
       "24326     stupid  1551\n",
       "2674       bitch  1531\n",
       "18733     people  1465\n",
       "5877        cunt  1452\n",
       "11496       hate  1444"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toxic_words.sort_values(by='freq', ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "4600ee88-7d1e-40f6-9082-6e98c3c26932",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8366</th>\n",
       "      <td>article</td>\n",
       "      <td>47509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145341</th>\n",
       "      <td>wikipedia</td>\n",
       "      <td>35065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96649</th>\n",
       "      <td>page</td>\n",
       "      <td>34884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146787</th>\n",
       "      <td>would</td>\n",
       "      <td>29296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129500</th>\n",
       "      <td>talk</td>\n",
       "      <td>25854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101372</th>\n",
       "      <td>please</td>\n",
       "      <td>23035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94385</th>\n",
       "      <td>one</td>\n",
       "      <td>22945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76497</th>\n",
       "      <td>like</td>\n",
       "      <td>20217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117466</th>\n",
       "      <td>see</td>\n",
       "      <td>16975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4274</th>\n",
       "      <td>also</td>\n",
       "      <td>16237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132217</th>\n",
       "      <td>think</td>\n",
       "      <td>16008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72500</th>\n",
       "      <td>know</td>\n",
       "      <td>13951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39987</th>\n",
       "      <td>edit</td>\n",
       "      <td>13837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99014</th>\n",
       "      <td>people</td>\n",
       "      <td>13777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139559</th>\n",
       "      <td>use</td>\n",
       "      <td>13493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8394</th>\n",
       "      <td>articles</td>\n",
       "      <td>13319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81659</th>\n",
       "      <td>may</td>\n",
       "      <td>12561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133010</th>\n",
       "      <td>time</td>\n",
       "      <td>12189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131512</th>\n",
       "      <td>thanks</td>\n",
       "      <td>10978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29074</th>\n",
       "      <td>could</td>\n",
       "      <td>10374</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             word   freq\n",
       "8366      article  47509\n",
       "145341  wikipedia  35065\n",
       "96649        page  34884\n",
       "146787      would  29296\n",
       "129500       talk  25854\n",
       "101372     please  23035\n",
       "94385         one  22945\n",
       "76497        like  20217\n",
       "117466        see  16975\n",
       "4274         also  16237\n",
       "132217      think  16008\n",
       "72500        know  13951\n",
       "39987        edit  13837\n",
       "99014      people  13777\n",
       "139559        use  13493\n",
       "8394     articles  13319\n",
       "81659         may  12561\n",
       "133010       time  12189\n",
       "131512     thanks  10978\n",
       "29074       could  10374"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nontoxic_words.sort_values(by='freq', ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b1e77da-8af3-42d5-9335-4146e0c654f2",
   "metadata": {},
   "source": [
    "# Feature Engineering\n",
    "\n",
    "In this section, we'll perform feature engineering. Because our main data is text, we won't do the numerical and image feature engineering here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "3b3542fa-777a-4670-9250-5567835a444c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_preprocessed, x_valid_preprocessed, x_test_preprocessed = x_preprocessed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a926bfd-a3ae-4b12-bbef-d4e2d51fb364",
   "metadata": {},
   "source": [
    "So, what can we do with text data?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c4f0d0-11d5-4f26-98c1-8312967b1757",
   "metadata": {},
   "source": [
    "- Add new features:\n",
    "  - Count-based features\n",
    "    - Number of unique words / n_words in text: Toxic comments might use repetitive negative words. Can be helpful(?)\n",
    "    - Number of punctuations: Maybe number of exclamation point? Toxic comments might used many of these.\n",
    "    - Ratio of uppercase words: Offensive comment might use more uppercase. \"blablabla FCK YOU PIECE OF SHT blablbla\"\n",
    "    - etc. (explore features that might help your model as many as possible)\n",
    "  - Score-based features\n",
    "    - Text polarity\n",
    "    - Text subjectivity\n",
    "  - Language features\n",
    "    - part-of-speech (POS) tagging\n",
    "    - Dependency parsing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4da2cb1c-b6da-42e1-89a9-e8da30b56651",
   "metadata": {},
   "source": [
    "- Converting text to vectors:\n",
    "  - Bag of words\n",
    "  - TF-IDF (We'll use this)\n",
    "  - Word Embedding\n",
    " \n",
    "Now for simplicity, we'll use the **TF-IDF** only. \n",
    "\n",
    "Some count-based features must be done parallel with data preprocessing. Because in the previous data preprocessing step, we have lowercased the text, removed punctuations, etc.\n",
    "\n",
    "We could do the text polarity and subjectivity, but let's put them aside first.\n",
    "\n",
    "Language features are also feasible to be added. But it's too complex and it seems won't help that much.\n",
    "\n",
    "When you are doing **real project** you might need to make some experiments for feature engineering. Feature engineering need to be done **iteratively** not **one pass**. \n",
    "\n",
    "But always do the **simplest** for 1st iteration. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "836b9c30-9714-4de4-ab57-abec09f24f73",
   "metadata": {},
   "source": [
    "## TF-IDF\n",
    "\n",
    "TF-IDF stands for Term Frequency Inverse Document Frequency of records. It can be defined as the calculation of how relevant a word in a series or corpus is to a text. The significance increases proportionally to the number of times in the text a word appears but is compensated by the word frequency in the corpus (data-set).\n",
    "\n",
    "Let's see how basic TF-IDF works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "adc05fb4-59dd-4cdf-9ba0-8625ddf63b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(\n",
    "    analyzer='word',\n",
    "    stop_words='english'\n",
    ")\n",
    "X_new = vectorizer.fit_transform(x_train_preprocessed['comment_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9911bb8c-7cda-4a29-ba03-ebe6824f046f",
   "metadata": {},
   "source": [
    "Now, let's see the token in the vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "3dc91360-ec06-4008-a4a4-bb0a9b170b55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['aa', 'aaa', 'aaaa', 'aaaaa', 'aaaaaaaa',\n",
       "       'aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaalllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllll',\n",
       "       'aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaahhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhh',\n",
       "       'aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaahhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhh',\n",
       "       'aaaaaaaaaaaaaaaaaaggggggggggggggggggggggggggggggggggggggggggggggg',\n",
       "       'aaaaaaaaaaaahahahahahahaaaaaaaaaaaaaahahahahahaaaaaaaaaaaaaaahahahahaaaaaaaaaaaaaaaaaaaaaaa',\n",
       "       'aaaaaaaaaaarrrrrrrrrggggggg', 'aaaaaaaaaah',\n",
       "       'aaaaaaaaaahhhhhhhhhhhhhh', 'aaaaaaaaadm',\n",
       "       'aaaaaaaahhhhhhhhhhhhhhhhhhhhhhh',\n",
       "       'aaaaaaaahhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhh',\n",
       "       'aaaaaaaarrrrrrrrgggggggghhhhhhhhh',\n",
       "       'aaaaaaahhhhhhhhhhhhhhhhhhhhhhhh', 'aaaaaaw', 'aaaaah', 'aaaaargh',\n",
       "       'aaaaarrrrrrggggghhhhh', 'aaaall', 'aaaand', 'aaaarrrggghhhh',\n",
       "       'aaaawwww', 'aaages', 'aaagh', 'aaaghh', 'aaah', 'aaahhh', 'aaahs',\n",
       "       'aaai', 'aaajade', 'aaand', 'aaarrrgggh', 'aaassssss', 'aab',\n",
       "       'aaberg', 'aabove', 'aac', 'aacargo', 'aachen', 'aachi', 'aacs',\n",
       "       'aadd', 'aadhaar', 'aadil', 'aadmi', 'aadministrators', 'aaf',\n",
       "       'aafakhravar', 'aafco', 'aafia', 'aaflight', 'aafs', 'aagadu',\n",
       "       'aage', 'aagf', 'aagin', 'aah', 'aahahahahahaha', 'aahank', 'aahh',\n",
       "       'aahhaha', 'aahil', 'aahoa', 'aai', 'aaiha', 'aajacksoniv',\n",
       "       'aajonus', 'aajyjsk', 'aake', 'aal', 'aaleksei', 'aaliya',\n",
       "       'aaliyah', 'aaliyahremembered', 'aall', 'aalst', 'aam', 'aambis',\n",
       "       'aamer', 'aamir', 'aamirjamil', 'aamof', 'aamovement', 'aams',\n",
       "       'aan', 'aancc', 'aand', 'aanda', 'aanddd', 'aanders', 'aanestad',\n",
       "       'aang', 'aankomst', 'aao', 'aaot', 'aap'], dtype=object)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_feature_names_out()[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b34d9a92-08bc-43f4-aef7-8707faf9a202",
   "metadata": {},
   "source": [
    "Some tokens are \"meaningless\". This is expected since we are using noisy text. For further reference, you might find more techniques discussed at workshops like the Workshop on Noisy User-generated Text. For now, let's explore the document frequency and see whether this might tell us something."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "44b2ba50-d825-489e-98cf-eefa180d68e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.histplot(\n",
    "    x=np.log(np.array(X_new.astype(bool).mean(axis=0)).flatten()),\n",
    "    bins=100\n",
    ")\n",
    "plt.xlabel('log(df)');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b9503db-17e2-445b-875d-918cb4c7692f",
   "metadata": {},
   "source": [
    "What are the most frequent occuring words and the least frequent?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "06b4e045-a72a-401b-919a-3fbee428a9a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>df</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>138961</th>\n",
       "      <td>time</td>\n",
       "      <td>0.077853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41788</th>\n",
       "      <td>edit</td>\n",
       "      <td>0.080338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103495</th>\n",
       "      <td>people</td>\n",
       "      <td>0.081395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75891</th>\n",
       "      <td>know</td>\n",
       "      <td>0.091728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138137</th>\n",
       "      <td>think</td>\n",
       "      <td>0.102016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80036</th>\n",
       "      <td>like</td>\n",
       "      <td>0.131663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135307</th>\n",
       "      <td>talk</td>\n",
       "      <td>0.147669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151827</th>\n",
       "      <td>wikipedia</td>\n",
       "      <td>0.162798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101034</th>\n",
       "      <td>page</td>\n",
       "      <td>0.166129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8655</th>\n",
       "      <td>article</td>\n",
       "      <td>0.203541</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            token        df\n",
       "138961       time  0.077853\n",
       "41788        edit  0.080338\n",
       "103495     people  0.081395\n",
       "75891        know  0.091728\n",
       "138137      think  0.102016\n",
       "80036        like  0.131663\n",
       "135307       talk  0.147669\n",
       "151827  wikipedia  0.162798\n",
       "101034       page  0.166129\n",
       "8655      article  0.203541"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 10 most frequent\n",
    "pd.DataFrame({\n",
    "    'token': vectorizer.get_feature_names_out(),\n",
    "    'df': np.array(X_new.astype(bool).mean(axis=0)).flatten()\n",
    "}).sort_values('df').tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "14d7bc35-518b-46ac-9371-558379863992",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>df</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>158406</th>\n",
       "      <td>𐌴𐌹</td>\n",
       "      <td>0.000008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82792</th>\n",
       "      <td>madhi</td>\n",
       "      <td>0.000008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82791</th>\n",
       "      <td>madhhabs</td>\n",
       "      <td>0.000008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82790</th>\n",
       "      <td>madhhab</td>\n",
       "      <td>0.000008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82789</th>\n",
       "      <td>madhesis</td>\n",
       "      <td>0.000008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82788</th>\n",
       "      <td>madhavpur</td>\n",
       "      <td>0.000008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82787</th>\n",
       "      <td>madhavan</td>\n",
       "      <td>0.000008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82786</th>\n",
       "      <td>madhani</td>\n",
       "      <td>0.000008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82785</th>\n",
       "      <td>madhai</td>\n",
       "      <td>0.000008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82784</th>\n",
       "      <td>madhab</td>\n",
       "      <td>0.000008</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            token        df\n",
       "158406         𐌴𐌹  0.000008\n",
       "82792       madhi  0.000008\n",
       "82791    madhhabs  0.000008\n",
       "82790     madhhab  0.000008\n",
       "82789    madhesis  0.000008\n",
       "82788   madhavpur  0.000008\n",
       "82787    madhavan  0.000008\n",
       "82786     madhani  0.000008\n",
       "82785      madhai  0.000008\n",
       "82784      madhab  0.000008"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 10 least frequent\n",
    "pd.DataFrame({\n",
    "    'token': vectorizer.get_feature_names_out(),\n",
    "    'df': np.array(X_new.astype(bool).mean(axis=0)).flatten()\n",
    "}).sort_values('df').head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb9e34ff-3746-4c61-bad4-465116dafa0b",
   "metadata": {},
   "source": [
    "In `tf-idf` we can remove the most frequent and/or the least frequent by using `max_df` and `min_df` argument in [tf-idf vectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html). This might affect the modeling result such as prevent overfitting.\n",
    "\n",
    "But the question is: \"What is the optimum value?\"\n",
    "\n",
    "Answer: we don't know, we could include this in the hyperparameter and optimize it. But now, let's try `min_df = 0.01`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "9d730b36-8d09-4e88-87ae-86ae499d8ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(\n",
    "    analyzer='word',\n",
    "    stop_words='english',\n",
    "    min_df = 1e-2\n",
    ")\n",
    "x_new = vectorizer.fit_transform(x_train_preprocessed['comment_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc66ec10-5324-494e-a098-ec764764ce0b",
   "metadata": {},
   "source": [
    "We aim to:\n",
    "- Make the function reusable\n",
    "- Fit vectorizer only to train data.\n",
    "- Transform valid and test using the previous vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "de787ced-4c8d-4481-9e72-562927520acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_tfidf(df_in, vectorizer=None):\n",
    "    df = df_in.copy()\n",
    "    if vectorizer is None:  # fit to train data\n",
    "        vectorizer = TfidfVectorizer(\n",
    "            analyzer='word',\n",
    "            stop_words='english',\n",
    "            min_df = 1e-2\n",
    "        )\n",
    "        vectorized = vectorizer.fit_transform(df['comment_text'])\n",
    "    else:\n",
    "        vectorized = vectorizer.transform(df['comment_text'])\n",
    "    \n",
    "    vectorized_df = pd.DataFrame(vectorized.toarray(), \n",
    "                                 columns=vectorizer.get_feature_names(), \n",
    "                                 index = df.index)\n",
    "    df_non_sentence = df.drop(['comment_text'],axis=1)\n",
    "    df_final = pd.concat([vectorized_df, df_non_sentence],axis=1)\n",
    "    return df_final, vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "6043f859-f8f3-4abb-9f10-8651985a7eee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ghifa\\documents\\pacmann\\simple-ml-project-example\\projectenv\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "df_train_vect, vectorizer = vectorize_tfidf(x_train_preprocessed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "941c33ce-2195-4da5-836c-e81003621f47",
   "metadata": {},
   "source": [
    "Now, we must save the vectorizer transforming the valid and test. But now, because we're working in the same jupyter notebook file. We can directly use the vectorizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "ddfa53fe-bfd2-46a9-8d87-edf6c627556c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ghifa\\documents\\pacmann\\simple-ml-project-example\\projectenv\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "c:\\users\\ghifa\\documents\\pacmann\\simple-ml-project-example\\projectenv\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "df_valid_vect, _ = vectorize_tfidf(x_valid_preprocessed, vectorizer)\n",
    "df_test_vect, _ = vectorize_tfidf(x_test_preprocessed, vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "cd3fabfa-e9ab-4b6a-a2da-89f0d3077e06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>able</th>\n",
       "      <th>according</th>\n",
       "      <th>account</th>\n",
       "      <th>actually</th>\n",
       "      <th>add</th>\n",
       "      <th>added</th>\n",
       "      <th>adding</th>\n",
       "      <th>address</th>\n",
       "      <th>admin</th>\n",
       "      <th>ago</th>\n",
       "      <th>...</th>\n",
       "      <th>write</th>\n",
       "      <th>writing</th>\n",
       "      <th>written</th>\n",
       "      <th>wrong</th>\n",
       "      <th>wrote</th>\n",
       "      <th>www</th>\n",
       "      <th>year</th>\n",
       "      <th>years</th>\n",
       "      <th>yes</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>162870</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10c4b10bd953900d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170883</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31ad9c8987c1a64c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175275</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.275854</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>436b574a54215710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28519</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4bda577fb3caa772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36661</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.560699</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6258dbad0e1b24da</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>644</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>01c10add8c4e0491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74556</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.270539</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>c858e7772e89b5b5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14097</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.248332</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2558cc6a8ad094eb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199420</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>a76bd844beda1649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196214</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9a0c7dc857f9fad4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>132391 rows × 381 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        able  according  account  actually       add     added  adding  \\\n",
       "162870   0.0        0.0      0.0  0.000000  0.000000  0.000000     0.0   \n",
       "170883   0.0        0.0      0.0  0.000000  0.000000  0.000000     0.0   \n",
       "175275   0.0        0.0      0.0  0.000000  0.275854  0.000000     0.0   \n",
       "28519    0.0        0.0      0.0  0.000000  0.000000  0.000000     0.0   \n",
       "36661    0.0        0.0      0.0  0.000000  0.000000  0.560699     0.0   \n",
       "...      ...        ...      ...       ...       ...       ...     ...   \n",
       "644      0.0        0.0      0.0  0.000000  0.000000  0.000000     0.0   \n",
       "74556    0.0        0.0      0.0  0.000000  0.000000  0.000000     0.0   \n",
       "14097    0.0        0.0      0.0  0.248332  0.000000  0.000000     0.0   \n",
       "199420   0.0        0.0      0.0  0.000000  0.000000  0.000000     0.0   \n",
       "196214   0.0        0.0      0.0  0.000000  0.000000  0.000000     0.0   \n",
       "\n",
       "        address  admin  ago  ...  write  writing  written     wrong  wrote  \\\n",
       "162870      0.0    0.0  0.0  ...    0.0      0.0      0.0  0.000000    0.0   \n",
       "170883      0.0    0.0  0.0  ...    0.0      0.0      0.0  0.000000    0.0   \n",
       "175275      0.0    0.0  0.0  ...    0.0      0.0      0.0  0.000000    0.0   \n",
       "28519       0.0    0.0  0.0  ...    0.0      0.0      0.0  0.000000    0.0   \n",
       "36661       0.0    0.0  0.0  ...    0.0      0.0      0.0  0.000000    0.0   \n",
       "...         ...    ...  ...  ...    ...      ...      ...       ...    ...   \n",
       "644         0.0    0.0  0.0  ...    0.0      0.0      0.0  0.000000    0.0   \n",
       "74556       0.0    0.0  0.0  ...    0.0      0.0      0.0  0.270539    0.0   \n",
       "14097       0.0    0.0  0.0  ...    0.0      0.0      0.0  0.000000    0.0   \n",
       "199420      0.0    0.0  0.0  ...    0.0      0.0      0.0  0.000000    0.0   \n",
       "196214      0.0    0.0  0.0  ...    0.0      0.0      0.0  0.000000    0.0   \n",
       "\n",
       "        www  year  years  yes                id  \n",
       "162870  0.0   0.0    0.0  0.0  10c4b10bd953900d  \n",
       "170883  0.0   0.0    0.0  0.0  31ad9c8987c1a64c  \n",
       "175275  0.0   0.0    0.0  0.0  436b574a54215710  \n",
       "28519   0.0   0.0    0.0  0.0  4bda577fb3caa772  \n",
       "36661   0.0   0.0    0.0  0.0  6258dbad0e1b24da  \n",
       "...     ...   ...    ...  ...               ...  \n",
       "644     0.0   0.0    0.0  0.0  01c10add8c4e0491  \n",
       "74556   0.0   0.0    0.0  0.0  c858e7772e89b5b5  \n",
       "14097   0.0   0.0    0.0  0.0  2558cc6a8ad094eb  \n",
       "199420  0.0   0.0    0.0  0.0  a76bd844beda1649  \n",
       "196214  0.0   0.0    0.0  0.0  9a0c7dc857f9fad4  \n",
       "\n",
       "[132391 rows x 381 columns]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_vect"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ab70944-7c26-491c-a19e-7d069f3daf1a",
   "metadata": {},
   "source": [
    "All is done! Well, id will not be used in modeling, later, the column `id` will be dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "f2765f64-8868-4849-b9ba-9ea38e46d7ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../output/x_test_vect.pkl']"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(df_train_vect, f\"../output/x_train_vect.pkl\")\n",
    "joblib.dump(df_valid_vect, f\"../output/x_valid_vect.pkl\")\n",
    "joblib.dump(df_test_vect, f\"../output/x_test_vect.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
